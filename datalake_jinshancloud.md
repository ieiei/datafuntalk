# 数据湖查询引擎架构和实践

导读：今天会分享金山云在数据湖查询引擎上的实践，以及实践当中遇到的问题和相应的解决方案。

总体分四个部分来分享：

1. 查询引擎架构简单介绍
2. 针对查询引擎做的功能和安全方面的增强实践
3. 不同查询引擎查询结构的差异
4. 针对查询性能提升的相关探索



## 01 数据湖查询引擎架构

查询引擎架构：根据客户具体使用场景，集成了Spark和Trino两种查询引擎。底层对接了两种数据湖和各种数据仓库，另外还集成了市面上常用的数据库。底层存储方面有常用的hdfs，以及市面上常用COS/S3等对象存储，包括hive和关系型数据库，中间使用alluxio做数据缓存来提升查询引擎效率。

如果只是简单的开源组件的集成并不能体现出整个查询引擎的优势。

因此我们还做了很多集成上的事情，在最顶上提供sql gateway。数据服务API类似的高速查询， 做ETL工作，或者数据分析场景，有的SQL运行时间很短，有的运行时间很长。这终场景下，对外统一提供查询引擎，对内根据各SQL特性选择更适合的引擎来提升查询任务。在此基础上，Gateway一方面做数据分析任务，另一方面做负载均衡相关的事情。从而整个查询引擎对外表现出来是整个无感透明的状态。 

上面提到整个架构是支持了flink和datax批量写入数据湖，

同时支持Spark和Trino两种查询引擎

也支持两种湖（hudi/iceberg）的数据结构，同时接入alluxio做数据缓存，提升热点数据查询效率。

同时对接入的数据源，还接入普通的数据源如JDBC，es，mongo的数据源；

集群运行在两种模式下，yarn环境和k8s环境。

## 02 查询引擎功能增强

如果只是简单的把这些模块简单的堆砌，是无法满足用户场景，对此我们对开源组件做了改进，是查询引擎功能有所增强

#### 1. 动态加载catalog

当前社区的trino版本是无法支持动态加载catalog

集群需要重启，实现动态加载。增加了部署和维护的成本，因此我们在开源的trino版本实现

用户侧通过http的请求来动态添加/删除catalog请求，trino commit 分发到各个worker节点，worker节点会实时响应请求，同时catalog信息存入数据库或者配置文件中。

当前开源的版本也在动态解决catalog的问题，开源版本还没有正式公开出来，只支持稳健的动态加载，不支持

我们是都加强，都可以存在， 以此实现动态源的加载



#### 2. 用户自定义函数方面

Trino已经支持用户自定义UDF功能，但是如果直接开发功能给用户使用，代码规范 代码是否存在内存泄漏等各种问题，如果这些问题没有被提前暴露出来，直接提交到trino集群内，在运行时由于某个UDF不符合规划，代码不理想，会造成整个集群性能下降，甚至集群奔溃。 我们采取把执行UDF功能从trino的架构中抽离出来，把执行的部署在一个或者多个的远程服务当中，当用户注册UDF，在trino侧只是注册了用户的路径和参数，具体执行是通过高速的RPC协议来实现高速通讯，在远端执行具体UDF计算的功能。 通过这样的架构，可以使UDF计算资源和trino集群自己的资源之间做很好的隔离，当用户提交的UDF存在某种缺陷时，可能只是这一次UDF的调用，或者UDF server集群内一个节点产生问题，其他集群不会有问题。这样可以很好的避免一个UDF问题造成整个trino集群资源的问题。

另外兼容spark UDF和hive UDF，这样通过一套机制同时执行Trino的UDF和Spark的UDF。

#### 3.多维度确保服务稳定

前面说的都是运行时的确保，但是在实际情况中， 当然可以在事后会看执行计划来判断是否有改善空间

- 事前检测

  如果我们能够提供一个对于SQL一个静态解析的方法，就可以在SQL提交之前，动态的检查SQL是否是一个满足规则的SQL，这样可以在另一个维度保证服务的稳定性，提供稳定的响应。  这是通过SQL的静态解析来实现， 解析过程中需要使用元数据，元数据除了字段列的信息定义，也包括统计信息（如limit条数，唯一值，最大值等等）。以及性能提示都有关。 语法只能提示包括是否会查询很多条数据，是否使用正确的分区字段， 开发了SQL预判的模型，另外对可能耗费大量资源的查询，比如大表join等比较危险和耗时的资源的SQL提示；

  另外支持SQL审计

通过事前检测，绝大多数SQL都可以提供解释给用户，用来判断是否需要的SQL做一些优化。 在SQL执行过程中

- 事中检测：（包括CPU，内存，扫描的数据）

  在执行中发现CPU内存达到集群上限阀值，是否全表扫描。提供是否终止SQL的方案，对最终SQL的优化做一些提示

- 资源监控

  对于集群的监控是达到集群每个节点的具体状态，包括CPU使用效率，内存，网络传输数据流带宽等指标做监控

通过这三点手段在SQL执行的开始和中间来解决SQL性能安全等问题。

#### 4. 数据访问权限控制

最后数数据安全相关的方向。对查询结果做一些敏感的脱敏

通过两个维度来解决：

1. 在应用层面：通过SQL的静态解析，从SQ当中提取出用户需要的源库，出现在查询结果，还是出现在filter， join 查询条件的位置， 在SQL中间出现位置的不同， 可以在业务层面限定：是否有查询的权限和是否需要做脱敏
2. 在物理层面：主要是结合Trino，以及Trino提供的相应插件的能力。另外我们也对于Trino的场景，hook JDBC获取元数据的方面，在元数据层面就可以跟用户权限挂钩。在元数据获取侧看不见，也能防止权限的泄漏

这样子两层限制更好的叠加在一起，做更好的保护。

## 03 不同查询引擎查询结果的差异

我们在具体应用方面因为集成了Spark/Trino两种查询引擎，来满足用户需求，但是也会带来一个很严重的问题。即不同的查询引擎对于相同的数据，包括一些特别的字段类型的数据，查询结果会有些差异。 这样会给用户带来一些困扰，比如去查同一张数据表，但是由于SQl写法不同，会造成查询结果或多或少的差异。 

对于这样情况，简单分享一下我们遇到的相关的问题：

#### Trino读取不到Hudi mor表的数据问题

- 问题：对Hudi的MOR表先做了insert的动作后，然后对其中一些数据做update，更新后数据在spark可以读到，但是在trino无法读取到更新后到数据，只能读到一开始insert后的那部分数据。
- 原因：分析原因，因为Hudi自己的特性的MOR有ro和rt两种表，trino的connector还不能够读取rt表中的日志文件，从而也不能够读到更新后的数据， 如果我们需要读取Hudi更新后的数据，就需要      或者换成Spark来读取
- 解决：在架构上我们提供了无数据的兼容，识别表最近机器执行执行的类型，动态切花查询的计算引擎使用哪个来避免这些问题。

#### Trino读Hudi的MOR原表问题：

- 问题：对于MOR分区表，内部是存在3种数据结构。  Spark创建的表，但是Trino无法读到Spark创建的原表的信息的。
- 原因：没有同步到
- 解决：如果我们在建表的时候在原始表的后面带上\_ro或者\_rt

#### Hudi的Timestamp类型读取问题

- 问题：在实践中发现，对于带时区的数据类型，比如Timestamp，Trino读取的结果和Spark或者Flink的结果会不一样，比如北京时间的话结果就会少8小时。
- 原因：Trino没有做转化
- 解决：在Trino源码上做适配，读取

#### Iceberg表时间精度和现实问题：（是个很细的点，看上图）

- 背景：
- 问题：
- 原因：
- 解决：

#### Hudi驱动包版本问题： （我们发现的很有趣的现象）

- 问题1:  当我们开启kerberos认证的情况下，Hudi不同版本
- 问题2:

## 04 查询性能提升探索

上面是我们在具体应用中发现的一些细的问题，最后分享我们在查询性能提升上的探索

#### 数仓-关系数据库优化

在上面架构图中有提到我们应用alluxio缓存来提升查询的方法

在源码角度：

- 一方面查询关系型数据库，如果关系型数据库的统计信息很完整的话，使用数据库的统计信息来优化数据库的执行效率。用tpcds的SQL来，  性能提升在19%左右。

- 另一方面，Oracle数据库的性能提升在50%左右， 可见元数据的统计信息对SQL查询有相当大的帮组。

这也带来了一个问题，当前统计信息不全，除非我们对表主动做analyze处理之后， 统计信息才会被收集   。 我们知道analyze是相当耗资源的，  

千万级以上或者上亿，执行analyze对于底层资源占用非常高，会影响使用，执行引擎无法提供服务

因此我们探索了通过底层HDFS

- 根据HDFS inotify监听写入和变更Event（过滤

周期性定时统计HDFS底层库的信息，包括计算出来小文件的数量，再通过小文件数量做阀值的报警，定义规则，提升HDFS本身的效率。 通过监听数据文件的变更。  通过两则完善统计信息。

#### z-order支持

最后探索中的方案：如果用户 排序，在查询测天生的支持返回的结果，通过实现数据写入后，自动的对数据进行z-order排序的功能，通过这样的手段，把落到盘上的数据文件。 当我们进行随机写入，orderBy的写入，通过z-order写入，提升的效率很明显。（该功能还在探索过程中）



## Q&A

1. 

Q: Trino能否在真正执行SQL前，预估出计算代价

A: 这不是Trino本身的， 是通过元数据信息来计算代码，通过静态解析工具来实现SQL计算代价的预估，包括经验累积， 历史执行计划的保存和汇总。还通过历史上对于相同表执行SQL的结果以及当前执行计划的汇总，通过事后分析，创建模型动态揣测， 做一些模型上的数据，对以后的执行检查做数据结果的支撑

Q：SQL的gateway是根据什么条件，做执行引擎的选择

A：客户写的SQL很可能是用一种特定的查询引擎，这里有两种情况，1特定SQL， 比如hiveSQL，sparkSQL，flinkSQL，都有特定的定义文件，通过这个文件来直白的区分使用引擎。2 通用的SQL， 类似数据服务的查询，还是想执行ETL和加工，通过这样的解析和规则命中。

