来聊一聊LLMOPS
LLMOPF该如何理解
LLM是指大语言模型,即大模型
OPS是指的平台和工具
那么完整定义就是基于大模型应用程序的生命周期、管理平台或者工具收回
大模型它主要分为三个阶段：
第一个阶段是预训练阶段，

预训练阶段是由数据集通过预训练产生预训练模型，这个过程是我们千模大战的主战场，各类开源闭源的大模型都是通过这个阶段产生。
第二个阶段是微调阶段，
微调阶段是指特定领域的数据集，在预训练模型的基础上面，通过finetune手段，产生特定领域的模型。
第三个阶段是应用开发阶段，
应用开发阶段，
只是在预训练模型和特定领域模型的推理功能之下，我们给他喂入我们的输入，以及我们经过提示工程进行指令编排，产生我们所需的大模型输出。
对于大模型应用平台来说，关注的阶段主要包括模型微调和应用开发阶段。
大模型应用主要的生命周期包括开发、部署配置和应用
为这里面，我们着重提出了一个配置的阶段，这与我们传统的应用程序可能会不大一样。
这是因为大模型里面非常核心的一个阶段
就是prompt engine提示工程
这个阶段类比于传统的应用程序的配置阶段
但它却是一个非常核心的阶段。
介绍完大模型的定义后，
我们先了解一下大模型的微调技术
在Bert出现之后，模型的微调技术得到广泛流行，即固定预训练模型的权重，根据具体任务在特定场景进行微调。
我们看右上这张图，各类开源大模型在特定领域数据进行加权设计之后，通过增量微调技术，产生的特定领域模型的一个过程。
这个过程是循环迭代，循环增强，不停的对各个领域的数据进行清洗补充之后，提升我们特定领域模型的效果，产生更强的模型。
目前通常使用的微调技术称作Peft，即参数高效微调技术。
这个技术在尽可能减少所需的参数和计算资源的情况下，实现对预训练语言模型的有效微调，解决了传统微调技术需要大量资源的问题。
在了解具体的微调技术之前，先对基础大模型进行简单的了解
目前的基础大模型主要有三个技术路线
一、BERT模式
二、GPT模式
三、混合模式
那么它发展历史是怎么样的呢
在Bert于18年提出之时
大模型真正开始比较流行的，那个时候流行的都是与BRT相似的
即是include only的一个架构
在19年基本上是独霸江湖
之后在19年谷歌提出了一个T5的模型
这个模型主要是为了解决test to test的统一框架结构。

这个模型也是取得了比较好的结果，引领了encoder到decoder的新一轮变革。
之后大概在20年，GPT3出来了，decode only架构已经开始慢慢的枝繁叶茂了
最后到22年的GPT横空出世，decode only目前看起来是大有一统江湖之势
我们来看一下三种架构的主要的区别
in cut to decoder又称为T5模式，它的训练就包括编码和减码阶段
然后主要的模型类型是判别式的
任务的类型是全面型
它主要的代表模型是T5呃
BRT以及GIM等等
第二个是Encode only，这是BERT模式。
这种模式的模型主要类型是派别式的，任务的类型是理解任务以及单任务模式
它的主要代表是BERT以及我们文心的早期版本
第三次Decode only，也就GPT模式
那么它采用的训练方式是自回馈
模型的类型是生成式类型
任务类型是生成类以及多任务
我们现在常见的GBT系列
以及bloom Namda Nama
bloom GBT等等都是采用这种方式
包括文心3.0也更改为这种模式
好那我们说回到大模型的微调技术
目前主要的一些微调技术
包括以下几种

1. adaptaning：
   adaptaning它的方式就是新增adapt的层在嵌入前方目的结构里面
   在训练时固定住原来的训练模型参数不变，只需要对新增的这层进行微调
   它优点是在只额外增加3.6%的参数规模下就相当于做了一次完整的finetune。

2. prefix turning：
   这是前缀的参略模式，在输入的TOKEN之前先构造一段任务相关的虚拟TOKEN（Virtual TOKEN）作为前缀，然后在训练的时候只更新前缀部分，在前方目里面，其他部分是固定的
   相比原来的finetune，对于不同的任务只需要不同的一个play fix就可以保证不同的训练效果

3. prompt turning：
   这是前缀preface turning的一个简化版本
   只要在输入层加入prompt TOKEN，并不需要加入MLP进行调整来解决比较难训练的问题。
   在这种情况，很多时候只需要调整最上面的一层，这是现在用的比较多的方式。
   只需要用虚拟训练模型比较足够强大
   那么prom的turn的结果
   会越越来越接近于我们做for fat turning

4. 那么接下来一种是pitering
   pitering的与probatering的区别是在于
   它将prompt的那层换成了embedding，embedding在实际上表应能力更强，它的优点就是微调参数只有0.65%，比之前的微调技术参数更少。

5. LoRA，LoRA是在整体的微调中
   在涉及矩阵相乘的模块引入a、b两个低矩阵的秩去模拟for for for attending
   也就是那个全全微调的逻辑
   这个好处在于他跟之前的所有推理方式都是正交的
   在推理阶段不会引入额外的计算量。

   

了解完当前主要的微调技术，我们来了解核心部分，即大模型应用构件的架构。

在应用构建过程，大模型平台需要为大模型应用的构建，提供便利的组件，以及具体的范式
然后提供快速搭建应用的能力
包括开发步骤运维
那么大模型应用主要应该如何来构建呢
首先需要了解到大模型的四个缺点：
第一个大模型是静态的，大模型训练成本比较高，它的所有的数据可能终止在某个时间点
在这之后的数据他没办法实时更新
而且大部分情况下
我们其实也没有很高的成本去做finetune
第二个缺点就是大模型的，对于特定领域的数据，特别是私有数据是没法获取到。
第三个缺点就是大模型的成本问题
那么他的没办法去做每个人
每个公司
或者个人开发没办法去做到我们的微调过程。在大部分情况下还是用云端的大模型
最后一个缺点是大模型它是一个黑盒，在很多情况下我们不知道大模型回答的东西，到底是它掌握的知识
还是它胡编乱造的，没有一个准确或者保真的逻辑在里面。基于此，大模型的应用主要构建逻辑就出来了。
第一阶段：
大模型的原生能力体现，也就是使用问题question、主题topic或者文档document，根据prompt与大模型交互产生需要的内容。
这里包括问答、改写、文档生成。包括知识推理，都可以去使用大模型原生的能力
但刚刚也提到，他没办法知道新的能力，也没办法知道私有化的数据。我们需要引入一个范式，叫做IG检索增强
检索增强生成是基于本地的知识库。为了增强它的语言理解，通常会使用如向量数据库的方式来构建。
在数据准备阶段，需要引入以下组件

1. connect，即数据准备。包括把文档数据，数据库的数据，数据流的数据等通过embedding向量的方式存到向量数据库里面，供IG调用。
   在大模型问答的过程中，Prompt可以通过IG去解锁最相近的一些文档知识，供大模型引用问答。
   这个情况下能保证知识的有效，准确真实。
   那么在有效准确真实之后
   我们需要扩展一些能力
   比如本地的一些API、数据库、或者说现实世界更多的知识被大模型给调用
   我们在这种情况下引入一个Tools（工具的使用）过程。
   我们可以把刚刚讲的API调用或者大模型的外部工具的使用，作为一个插件。在与大模型交互之前先通过工具去获取一些信息，再与大模型进行交互，达到一个增强的结果。这能极大的提升应用的交互能力。
   那么在应用构建中主要的模式难点
   大模型的应用天生是一个it的
   也就是智能体
   这是大模型应用搭建的核心方向
   是重点也是难点
   对于智能体来说
   大模型是核心
   完成对话和推理的任务
   具备一定的自主行为
   那么它需要以下的几个核心部件
   一个是工具
   就是TOS
   依赖大模型的一个防击靠的能力

2. 记忆，里面包括短期记忆和长期记忆。
   短期记忆是指大模型的上下文，需要大模型具备多轮对话能力。长期记忆就需要像数据库那样去存储交互的一些细节
   实际上知识库也可以认为是记忆的一种。毕竟人类的学习过程是存储记忆的一个过程。

3. 规划能力，只依赖我们大模型的一个内置COT，也就是思维链的能力。

   

在构建里面的难点提到了agent，agent主要包含以下几种类型：

- 第一种是自主式智能体。自主式智能体是指根据指令或者引导自动完成任务，达成目标结果。明确工具属性的一个智能体。
  目前主要的项目如AutoGPT，它是大模型思维链自主实现任务目标的一个项目

  第二是贝贝Agent，它基于前续任务结果和目标来创建新任务。

  第三个GBDA流量。它是根据向AI提供一些动人的解释或者指导来完成完整的代码库。

- 第二种是生存式智能体，这种智能体是模拟人类具备记忆和自主决策能力。但不是以服务人类为目标，而是以模仿为目标
  这里面的优秀项目，比如GBTM，它里面设置了很多智能体，每个智能体都有独立的记忆，能够相互的交流进行协作。
  第二是GBT Researcher。这是根据定制化的需求，甚至详细客观不带偏见的研究报告。
  第三种是Meta GBT，每台GPT是指多个智能的不同角色协作来完成一个复杂任务

这些agent在真正的落地过程中会碰到哪些难点呢？这边列出了5个难点：

- 第一个是可靠性。大模型的幻觉是非常难克服的点，经常在planting阶段或者说少载阶段会提出一些不真实或者环境无法满足的操作或者推论，导致应用比较难执行
- 第二是稳定性。大模型是非常随机性的，在用户多次结果中，可能会拿到一个截然不同的结论。
  对于生成式智能体，大家可能会觉得这个东西具有一定的吸引性。
  但是如果是放在具体的任务场景，会是比较难以接受。
- 第三个准确性。准确性对于大模型来说，还是它的知识欠缺的逻辑。
  我们需要给他一些参考的知识，基于参考知识来回答。受限于当前的搜索技术，在应用构建中，很难保证获得到的知识或者记忆是最相关。特别在IG系统里面，这会体现的特别明显。
- 最后是完整性。现在大模型的TOKEN一般来说比较限制的，如4096或者现在大家推的比较多一点的是6K。但也达不到一个文档的完整的长度。在这种情况下，我们不可能将一个完整的文档或者任务作为上下文投喂给大模型。
  这导致一些任务比如法规读取或者口点比较难取得很好的体验。
- 最终最后要考虑的一个问题就是成本。我们的智能体在实际的运用过程中，特别是比较复杂的一些诸如使用思维链或者react，这种弹模型交互的智能体。他需要与蛋白芯进行反复的交互。这即使这是一个极小的任务，也会产生比较高的一个成本。

针对以上难点，我们针对性的提出了相应的解决方案

1. 针对可靠性，稳定性问题。我们有个解决方案叫prompt ID，
   它的核心逻辑是为我们的提示词建立一个稳定可靠的解决方案
   promenade中文名可以称为提示词功能区
   主要的目的是为了保证与大模型交互的提质者
   能够最终产生一个稳定可靠的版本
   它的核心能力第一个是参数化模板
   参数化模板的作用
   主要是为了我们这个扩展
   或者批量量产数据
   它需要支持
   参数化的模板是自由替备参数
   提升Prompt的场景应用效率
   比如说你是一名什么职位
   我会提供一些与某些知识领域相关的话题。
   你的工作就是使用某种新闻风格，来为某类目标人群解释这些概念
   p题目相隔4点
   那这个地方我们有一些参数
   比如职位
   知识领域新闻风格和目标人群
   我们可以产生比如说100条的呃
   评测数据
   然后每个职位或者资质领域都会列一下
   然后再整理评的这个参数
   化模板的功能或者效果怎么样
2. 大模型的调试。不同大模型针对于指令或者具体的一些参数会有不一样的响应结果
   我们通常调的就是在提示工程词里面
   提示词里面加一些指令性的设置
   或者说我们在最后的那个参数
   也随机性上面去做一些调试
   那这个地方需要我们灵活，能够在不同档模型下快速的获得相应的结果来保证写Prompt的效率
3. 多版本的支持，大模型会有一个比较玄学的点，它不是线性也不是全能的。
   我们在不同版本的调优过程中可能会发现a版本对于a任务表现比较好，但是b版本是在a版本的基础上进行改良，针对于a任务确实效果更好，但是对于b任务来说，它效果反而降低了。
   在这种情况下，可能需要对于不同场景产生不同版本来进行沉淀。
   最后一个是批量化回测功能。这主要是因为Prompt的不稳定
   那我们怎么去评测Prompt的好坏。
   我们不可能针对一条数据就觉得这个Prompt的好
   也不能因为一条数据就直接将此Prompt pass，
   我们需要比如100条或者200条等的批量数据
   发起批量调用
   然后根据它的结果做一个呃标注
   然后认为它批量回测和评估的结果
   做一个优质结果的占比
   然后来更科学地评价Prom的优点
   这是针对于稳定和可靠的一个解决方案
   那么另外一个是针对于成本
   或者说我们效果的方案
   这个地方主要是一键的部署和监控
   一键部署主要是指我们大模型应用平台，能够让用户快速构建应用上线，并且能够在线调优实时部署。
   在整个SOP里能够获得一个比较好的体验，这就需要我们有以下核心功能。
   第一、低代码的构建，我们很多组件都需要去把它快速给沉淀下来。然后用户在这些组件的基础上能够快速搭建出相关的一个场景；
   第二、场景的模板化，我们搭建场景需要能尽可能的复用，因为大模型实际上很多的流程都是比较固定的，那么在提供了丰富的模板之后，能够快速孵化出一个新的场景；
   第三个是配置的在线化，即Prompt工程。它实际上能够快速的替换，快速的调节，让线上的一些效果快速的更改，调试发布上线。针对线上的效果，我们需要做到效果的监控和成本的监控。
   效果监控包括：

1. 针对于知识问答的点击场景，也是比较核心的场景。它依赖于召回结果的准确性，因此知识库的命中率和相关性的监控，就为这一效果做保证。

2. 敏感词调用。这是针对于大模型的监管问题。大模型通常来说会命中一些敏感词，导致输出结果异常。
   这通常是一些输入的问题，由于IG的影响，输入其实大部分是知识库的内容。
   因此知识库或者问题产生密度敏感会极大的降低用户的体验，或者产生不可预知的行为。
   在情况下，如何去评估知识库的好坏，实际上可以用敏感调用率来进行监控。来保证我们的场景是以极低风险在运行，
   而不是经常命中敏感词，导致应用不可用

   

最后是成本的考虑，我们需要一个token消耗监控。特别在改写或者agent的场景，在大模型进行多次交互过程中，消耗的token数量是非常可观的。企业在控制成本的考量下面，需要直观的获取每个场景token消耗速度，来保证核心成本不被浪费。

本次我们对于大模型应用平台LLMOPS的整体介绍到此结束。
